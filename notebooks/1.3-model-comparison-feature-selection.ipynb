{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, fbeta_score, make_scorer\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal model, F_beta score is applied in cross validation. beta equals to 2 indicates that we have a higher weight on the recall when selecting models . In other words, type II error will be weigh higher.\n",
    "\n",
    "When evaluating the test data, the main measure for deciding the optimal model will be the challenge metric (Total cost = Cost1 · `#type I failures` + Cost2 · `#type II failures`). Besides, F_beta score and classification reports of precision/recall will be applied when running the script as a reference for the model performance. Together with challenge metrics, F_beta scores are recorded as F2 scores.\n",
    "\n",
    "`#type I failures` is the count of type I failures (false positive), which indicates no faulty systems were reported positive falsely and leads to unnecessary mechanical check. While `#type II failures` is the count of type II failures (false negative), which indicates these problematic systems were reported no failure. The costs are 10 and 500 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/ida_2016_training_set_update.csv', na_values=['na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X and y\n",
    "X, y = data.drop(['class'], axis=1), data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickled imputer; SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "with open('../models/imputer.pkl','rb') as pickled_file:\n",
    "    imputer = joblib.load(pickled_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputate missing values by median\n",
    "X_imputed = pd.DataFrame(imputer.transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520.0</td>\n",
       "      <td>493384.0</td>\n",
       "      <td>721044.0</td>\n",
       "      <td>469792.0</td>\n",
       "      <td>339156.0</td>\n",
       "      <td>157956.0</td>\n",
       "      <td>73224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33058.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400.0</td>\n",
       "      <td>178064.0</td>\n",
       "      <td>293306.0</td>\n",
       "      <td>245416.0</td>\n",
       "      <td>133654.0</td>\n",
       "      <td>81140.0</td>\n",
       "      <td>97576.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41040.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.280000e+02</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378.0</td>\n",
       "      <td>159812.0</td>\n",
       "      <td>423992.0</td>\n",
       "      <td>409564.0</td>\n",
       "      <td>320746.0</td>\n",
       "      <td>158022.0</td>\n",
       "      <td>95128.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60874.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.368000e+03</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012.0</td>\n",
       "      <td>229790.0</td>\n",
       "      <td>405298.0</td>\n",
       "      <td>347188.0</td>\n",
       "      <td>286954.0</td>\n",
       "      <td>311560.0</td>\n",
       "      <td>433954.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
       "0  76698.0     0.0  2.130706e+09   280.0     0.0     0.0     0.0     0.0   \n",
       "1  33058.0     0.0  0.000000e+00   126.0     0.0     0.0     0.0     0.0   \n",
       "2  41040.0     0.0  2.280000e+02   100.0     0.0     0.0     0.0     0.0   \n",
       "3     12.0     0.0  7.000000e+01    66.0     0.0    10.0     0.0     0.0   \n",
       "4  60874.0     0.0  1.368000e+03   458.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   ag_002  ag_003  ...     ee_002    ee_003    ee_004    ee_005    ee_006  \\\n",
       "0     0.0     0.0  ...  1240520.0  493384.0  721044.0  469792.0  339156.0   \n",
       "1     0.0     0.0  ...   421400.0  178064.0  293306.0  245416.0  133654.0   \n",
       "2     0.0     0.0  ...   277378.0  159812.0  423992.0  409564.0  320746.0   \n",
       "3     0.0   318.0  ...      240.0      46.0      58.0      44.0      10.0   \n",
       "4     0.0     0.0  ...   622012.0  229790.0  405298.0  347188.0  286954.0   \n",
       "\n",
       "     ee_007    ee_008  ee_009  ef_000  eg_000  \n",
       "0  157956.0   73224.0     0.0     0.0     0.0  \n",
       "1   81140.0   97576.0  1500.0     0.0     0.0  \n",
       "2  158022.0   95128.0   514.0     0.0     0.0  \n",
       "3       0.0       0.0     0.0     4.0    32.0  \n",
       "4  311560.0  433954.0  1218.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed_scaled = X_imputed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled scaler; preprocessing.MinMaxScaler(feature_range = (0, 1))\n",
    "with open('../models/scaler.pkl','rb') as pickled_file: \n",
    "    scaler = joblib.load(pickled_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed_scaled = scaler.transform(X_imputed_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features can be irrelevant to the target variable and therefore create noise when fitting the algorithm. Due to highly correlated features in the data exploration step, it would be interesting to check feature importance and see if reduced features can improve model performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExtraTrees will be applied here to select features based on their importance. ExtraTrees is one extension of Random forest, which is also a well-known method to measure the feature importance. For the ExtraTrees method, a random value based on the empirical training set would be selected for the split. The strength of the randomness is could choose an appropriate parameter based on the problem specifics. This algorithm would result in a vector of input feature importance, ranged from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreeClassifier(random_state=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the ExtraTreesClassifier model for feature selection\n",
    "forest = ExtraTreeClassifier(random_state=3)\n",
    "\n",
    "# Fit forest using all Xs and y's\n",
    "forest.fit(X_imputed_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 24 - ao_000 (0.164575)\n",
      "2. feature 81 - bt_000 (0.079826)\n",
      "3. feature 49 - az_006 (0.022841)\n",
      "4. feature 164 - ee_005 (0.020417)\n",
      "5. feature 55 - ba_002 (0.018982)\n",
      "6. feature 25 - ap_000 (0.016529)\n",
      "7. feature 40 - ay_007 (0.016008)\n",
      "8. feature 52 - az_009 (0.015659)\n",
      "9. feature 22 - am_0 (0.014874)\n",
      "10. feature 98 - cl_000 (0.014864)\n",
      "11. feature 142 - dm_000 (0.014718)\n",
      "12. feature 20 - ak_000 (0.014637)\n",
      "13. feature 165 - ee_006 (0.014325)\n",
      "14. feature 39 - ay_006 (0.013545)\n",
      "15. feature 9 - ag_002 (0.010987)\n",
      "16. feature 82 - bu_000 (0.010905)\n",
      "17. feature 158 - ed_000 (0.009921)\n",
      "18. feature 12 - ag_005 (0.009184)\n",
      "19. feature 96 - cj_000 (0.008785)\n",
      "20. feature 134 - de_000 (0.008404)\n",
      "21. feature 74 - bm_000 (0.008352)\n",
      "22. feature 84 - bx_000 (0.008155)\n",
      "23. feature 79 - br_000 (0.008126)\n",
      "24. feature 160 - ee_001 (0.007637)\n",
      "25. feature 21 - al_000 (0.007342)\n",
      "26. feature 58 - ba_005 (0.007320)\n",
      "27. feature 8 - ag_001 (0.007221)\n",
      "28. feature 99 - cm_000 (0.007183)\n",
      "29. feature 43 - az_000 (0.006930)\n",
      "30. feature 100 - cn_000 (0.006926)\n",
      "31. feature 7 - ag_000 (0.006887)\n",
      "32. feature 115 - cs_001 (0.006845)\n",
      "33. feature 118 - cs_004 (0.006699)\n",
      "34. feature 0 - class (0.006626)\n",
      "35. feature 66 - be_000 (0.006395)\n",
      "36. feature 77 - bp_000 (0.006367)\n",
      "37. feature 85 - by_000 (0.006292)\n",
      "38. feature 117 - cs_003 (0.006231)\n",
      "39. feature 113 - cr_000 (0.006098)\n",
      "40. feature 150 - du_000 (0.005942)\n",
      "41. feature 42 - ay_009 (0.005835)\n",
      "42. feature 111 - cp_000 (0.005711)\n",
      "43. feature 18 - ai_000 (0.005612)\n",
      "44. feature 69 - bh_000 (0.005596)\n",
      "45. feature 71 - bj_000 (0.005527)\n",
      "46. feature 166 - ee_007 (0.005440)\n",
      "47. feature 148 - ds_000 (0.005332)\n",
      "48. feature 76 - bo_000 (0.005330)\n",
      "49. feature 17 - ah_000 (0.005273)\n",
      "50. feature 59 - ba_006 (0.005249)\n",
      "51. feature 37 - ay_004 (0.005204)\n",
      "52. feature 101 - cn_001 (0.005079)\n",
      "53. feature 116 - cs_002 (0.005064)\n",
      "54. feature 44 - az_001 (0.004834)\n",
      "55. feature 135 - df_000 (0.004758)\n",
      "56. feature 80 - bs_000 (0.004743)\n",
      "57. feature 23 - an_000 (0.004616)\n",
      "58. feature 88 - cb_000 (0.004613)\n",
      "59. feature 159 - ee_000 (0.004513)\n",
      "60. feature 131 - db_000 (0.004438)\n",
      "61. feature 97 - ck_000 (0.004418)\n",
      "62. feature 10 - ag_003 (0.004379)\n",
      "63. feature 152 - dx_000 (0.004375)\n",
      "64. feature 104 - cn_004 (0.004368)\n",
      "65. feature 90 - cd_000 (0.004323)\n",
      "66. feature 147 - dr_000 (0.004292)\n",
      "67. feature 119 - cs_005 (0.004282)\n",
      "68. feature 87 - ca_000 (0.004269)\n",
      "69. feature 67 - bf_000 (0.004240)\n",
      "70. feature 163 - ee_004 (0.004190)\n",
      "71. feature 167 - ee_008 (0.004162)\n",
      "72. feature 128 - cy_000 (0.004148)\n",
      "73. feature 32 - ax_000 (0.004132)\n",
      "74. feature 149 - dt_000 (0.004120)\n",
      "75. feature 60 - ba_007 (0.004047)\n",
      "76. feature 34 - ay_001 (0.004001)\n",
      "77. feature 53 - ba_000 (0.003968)\n",
      "78. feature 83 - bv_000 (0.003926)\n",
      "79. feature 156 - eb_000 (0.003870)\n",
      "80. feature 161 - ee_002 (0.003865)\n",
      "81. feature 13 - ag_006 (0.003841)\n",
      "82. feature 102 - cn_002 (0.003825)\n",
      "83. feature 64 - bc_000 (0.003728)\n",
      "84. feature 107 - cn_007 (0.003706)\n",
      "85. feature 57 - ba_004 (0.003689)\n",
      "86. feature 136 - dg_000 (0.003556)\n",
      "87. feature 70 - bi_000 (0.003543)\n",
      "88. feature 68 - bg_000 (0.003498)\n",
      "89. feature 125 - cu_000 (0.003411)\n",
      "90. feature 30 - au_000 (0.003410)\n",
      "91. feature 143 - dn_000 (0.003393)\n",
      "92. feature 11 - ag_004 (0.003358)\n",
      "93. feature 48 - az_005 (0.003349)\n",
      "94. feature 46 - az_003 (0.003309)\n",
      "95. feature 95 - ci_000 (0.003249)\n",
      "96. feature 56 - ba_003 (0.003201)\n",
      "97. feature 28 - as_000 (0.003167)\n",
      "98. feature 162 - ee_003 (0.003126)\n",
      "99. feature 3 - ac_000 (0.003110)\n",
      "100. feature 61 - ba_008 (0.003046)\n",
      "101. feature 120 - cs_006 (0.002983)\n",
      "102. feature 15 - ag_008 (0.002974)\n",
      "103. feature 109 - cn_009 (0.002705)\n",
      "104. feature 94 - ch_000 (0.002634)\n",
      "105. feature 157 - ec_00 (0.002586)\n",
      "106. feature 144 - do_000 (0.002564)\n",
      "107. feature 16 - ag_009 (0.002564)\n",
      "108. feature 110 - co_000 (0.002556)\n",
      "109. feature 19 - aj_000 (0.002533)\n",
      "110. feature 121 - cs_007 (0.002505)\n",
      "111. feature 54 - ba_001 (0.002503)\n",
      "112. feature 108 - cn_008 (0.002428)\n",
      "113. feature 65 - bd_000 (0.002424)\n",
      "114. feature 45 - az_002 (0.002396)\n",
      "115. feature 92 - cf_000 (0.002355)\n",
      "116. feature 105 - cn_005 (0.002325)\n",
      "117. feature 114 - cs_000 (0.002300)\n",
      "118. feature 29 - at_000 (0.002240)\n",
      "119. feature 38 - ay_005 (0.002228)\n",
      "120. feature 14 - ag_007 (0.002215)\n",
      "121. feature 75 - bn_000 (0.002169)\n",
      "122. feature 106 - cn_006 (0.002132)\n",
      "123. feature 72 - bk_000 (0.002111)\n",
      "124. feature 103 - cn_003 (0.002033)\n",
      "125. feature 78 - bq_000 (0.001972)\n",
      "126. feature 146 - dq_000 (0.001929)\n",
      "127. feature 73 - bl_000 (0.001928)\n",
      "128. feature 51 - az_008 (0.001917)\n",
      "129. feature 41 - ay_008 (0.001907)\n",
      "130. feature 123 - cs_009 (0.001904)\n",
      "131. feature 62 - ba_009 (0.001828)\n",
      "132. feature 50 - az_007 (0.001814)\n",
      "133. feature 26 - aq_000 (0.001783)\n",
      "134. feature 36 - ay_003 (0.001777)\n",
      "135. feature 137 - dh_000 (0.001751)\n",
      "136. feature 5 - ae_000 (0.001741)\n",
      "137. feature 1 - aa_000 (0.001716)\n",
      "138. feature 33 - ay_000 (0.001699)\n",
      "139. feature 35 - ay_002 (0.001674)\n",
      "140. feature 124 - ct_000 (0.001560)\n",
      "141. feature 133 - dd_000 (0.001556)\n",
      "142. feature 47 - az_004 (0.001537)\n",
      "143. feature 2 - ab_000 (0.001469)\n",
      "144. feature 132 - dc_000 (0.001441)\n",
      "145. feature 145 - dp_000 (0.001433)\n",
      "146. feature 127 - cx_000 (0.001389)\n",
      "147. feature 6 - af_000 (0.001365)\n",
      "148. feature 112 - cq_000 (0.001339)\n",
      "149. feature 151 - dv_000 (0.001259)\n",
      "150. feature 31 - av_000 (0.001112)\n",
      "151. feature 63 - bb_000 (0.001056)\n",
      "152. feature 91 - ce_000 (0.000847)\n",
      "153. feature 86 - bz_000 (0.000695)\n",
      "154. feature 168 - ee_009 (0.000645)\n",
      "155. feature 155 - ea_000 (0.000618)\n",
      "156. feature 126 - cv_000 (0.000427)\n",
      "157. feature 4 - ad_000 (0.000224)\n",
      "158. feature 139 - dj_000 (0.000000)\n",
      "159. feature 130 - da_000 (0.000000)\n",
      "160. feature 129 - cz_000 (0.000000)\n",
      "161. feature 27 - ar_000 (0.000000)\n",
      "162. feature 154 - dz_000 (0.000000)\n",
      "163. feature 153 - dy_000 (0.000000)\n",
      "164. feature 140 - dk_000 (0.000000)\n",
      "165. feature 122 - cs_008 (0.000000)\n",
      "166. feature 138 - di_000 (0.000000)\n",
      "167. feature 89 - cc_000 (0.000000)\n",
      "168. feature 93 - cg_000 (0.000000)\n",
      "169. feature 141 - dl_000 (0.000000)\n",
      "170. feature 169 - ef_000 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "columns = data.columns\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d - %s (%f)\" % (f + 1, indices[f], columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying ExtraTrees on the features, we got all 170 importance scores. The detailed scores and the feature rankings are shown as above. \n",
    "\n",
    "From previous sections of XGBoost and Logistic Regression models, we can select two optimal approaches - Logistic Regression with grid search CV and XGBoost with ‘scale_pos_weight’ equals to 59. In this experiment, we will use two sets of reduced features for training and evaluating these two optimal models - one set with features whose importance scores are larger than 0.005, the other set with importance scores that are larger than 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features that have importance scores less than 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44, 135,  80,  23,  88, 159, 131,  97,  10, 152, 104,  90, 147,\n",
       "       119,  87,  67, 163, 167, 128,  32, 149,  60,  34,  53,  83, 156,\n",
       "       161,  13, 102,  64, 107,  57, 136,  70,  68, 125,  30, 143,  11,\n",
       "        48,  46,  95,  56,  28, 162,   3,  61, 120,  15, 109,  94, 157,\n",
       "       144,  16, 110,  19, 121,  54, 108,  65,  45,  92, 105, 114,  29,\n",
       "        38,  14,  75, 106,  72, 103,  78, 146,  73,  51,  41, 123,  62,\n",
       "        50,  26,  36, 137,   5,   1,  33,  35, 124, 133,  47,   2, 132,\n",
       "       145, 127,   6, 112, 151,  31,  63,  91,  86, 168, 155, 126,   4,\n",
       "       139, 130, 129,  27, 154, 153, 140, 122, 138,  89,  93, 141, 169])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[53:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0048344 , 0.00475843, 0.00474338, 0.00461557, 0.00461312,\n",
       "       0.00451327, 0.00443795, 0.00441762, 0.00437936, 0.0043751 ,\n",
       "       0.00436766, 0.00432342, 0.00429241, 0.00428164, 0.00426892,\n",
       "       0.00423991, 0.00418961, 0.00416185, 0.00414792, 0.00413232,\n",
       "       0.00412034, 0.0040471 , 0.00400137, 0.00396809, 0.00392587,\n",
       "       0.00387013, 0.0038654 , 0.00384064, 0.00382504, 0.00372782,\n",
       "       0.00370615, 0.00368909, 0.00355614, 0.00354263, 0.00349789,\n",
       "       0.00341123, 0.00341025, 0.00339257, 0.00335813, 0.00334912,\n",
       "       0.00330861, 0.0032489 , 0.00320097, 0.00316659, 0.00312591,\n",
       "       0.00311014, 0.003046  , 0.00298344, 0.00297381, 0.00270455,\n",
       "       0.00263384, 0.00258637, 0.00256436, 0.00256414, 0.00255631,\n",
       "       0.00253322, 0.00250537, 0.00250287, 0.00242797, 0.00242353,\n",
       "       0.00239558, 0.00235547, 0.00232542, 0.0023002 , 0.00224042,\n",
       "       0.00222781, 0.0022155 , 0.00216884, 0.00213165, 0.00211113,\n",
       "       0.00203299, 0.00197213, 0.00192901, 0.00192761, 0.00191748,\n",
       "       0.00190709, 0.00190377, 0.00182809, 0.00181356, 0.00178293,\n",
       "       0.00177718, 0.00175148, 0.00174134, 0.00171642, 0.0016989 ,\n",
       "       0.00167419, 0.00155968, 0.00155588, 0.00153707, 0.0014685 ,\n",
       "       0.00144149, 0.0014327 , 0.00138859, 0.00136538, 0.00133852,\n",
       "       0.00125928, 0.00111176, 0.00105636, 0.00084746, 0.00069487,\n",
       "       0.00064515, 0.00061784, 0.00042705, 0.00022433, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances[indices[53:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['az_001', 'df_000', 'bs_000', 'an_000', 'cb_000', 'ee_000', 'db_000',\n",
       "       'ck_000', 'ag_003', 'dx_000',\n",
       "       ...\n",
       "       'ar_000', 'dz_000', 'dy_000', 'dk_000', 'cs_008', 'di_000', 'cc_000',\n",
       "       'cg_000', 'dl_000', 'ef_000'],\n",
       "      dtype='object', length=117)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_features = columns[indices[53:]]\n",
    "removed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure the dataset by removing these less importatnt features\n",
    "X_new = np.delete(X_imputed_scaled, indices[53:] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 53)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training/testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find best parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the total cost (competition metric)\n",
    "def get_total_cost(type1_error, type2_error, cost1 = 10,cost2 = 500):\n",
    "    # type II error: FN, cost=500\n",
    "    # type I error: FP, cost=10\n",
    "    return type1_error*cost1 + type2_error*cost2\n",
    "\n",
    "# Function to get prettified confusion matrix\n",
    "def get_confusion_matrix(y_pred, y_true=y_test):\n",
    "    confusion_matrix_df = pd.DataFrame(\n",
    "        confusion_matrix(y_true, y_pred, labels=['pos', 'neg']),\n",
    "        index=['True:pos', 'True:neg'], \n",
    "        columns=['Pred:pos', 'Pred:neg']\n",
    "    )\n",
    "    \n",
    "    return confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 5-fold splits in applying CV, random_state is fixed\n",
    "fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A grid of parameter 'C' in logistic regresssion\n",
    "params_grid = {'C': np.power(10.0, np.arange(-5, 5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(random_state=3, class_weight='balanced', max_iter=3000, verbose=1)\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2, pos_label='pos')\n",
    "grid_search_cv_models = GridSearchCV(lr_model, params_grid, cv=fold, scoring=ftwo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=3, shuffle=True),\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=3000, random_state=3,\n",
       "                                          verbose=1),\n",
       "             param_grid={'C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04])},\n",
       "             scoring=make_scorer(fbeta_score, beta=2, pos_label=pos))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CV model for logistic regression\n",
    "grid_search_cv_models.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score during training: 0.6787490984756834, with params: {'C': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print(f'The best score during training: {grid_search_cv_models.best_score_}, with params: {grid_search_cv_models.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_cv_models.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "           Pred:pos  Pred:neg\n",
      "True:pos       189        11\n",
      "True:neg       317     11483\n"
     ]
    }
   ],
   "source": [
    "conf_mat = get_confusion_matrix(y_pred)\n",
    "print(f'Confusion matrix:\\n {conf_mat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 8670\n"
     ]
    }
   ],
   "source": [
    "total_cost = get_total_cost(type1_error=317, type2_error=11)\n",
    "print(f'Total cost: {total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.97      0.99     11800\n",
      "         pos       0.37      0.94      0.54       200\n",
      "\n",
      "    accuracy                           0.97     12000\n",
      "   macro avg       0.69      0.96      0.76     12000\n",
      "weighted avg       0.99      0.97      0.98     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score: 0.7235834609494639\n"
     ]
    }
   ],
   "source": [
    "ftwo_score = fbeta_score(y_test, y_pred, beta=2, pos_label='pos')\n",
    "\n",
    "print(f'F2 score: {ftwo_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'scale_pos_weight' value is used to scale the gradient for the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate scale_pos_weight value\n",
    "estimate = 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric='aucpr', random_state=3, scale_pos_weight=estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_beta_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    beta = 2 # Less weight on precision, more weight on recall\n",
    "    return 'ftwo_score', fbeta_score(y_pred, y_true, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='aucpr',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=3, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=59, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "           Pred:pos  Pred:neg\n",
      "True:pos       157        43\n",
      "True:neg        35     11765\n"
     ]
    }
   ],
   "source": [
    "conf_mat2 = get_confusion_matrix(y_pred2)\n",
    "print(f'Confusion matrix:\\n {conf_mat2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 21850\n"
     ]
    }
   ],
   "source": [
    "total_cost2 = get_total_cost(type1_error=35, type2_error=43)\n",
    "print(f'Total cost: {total_cost2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00     11800\n",
      "         pos       0.82      0.79      0.80       200\n",
      "\n",
      "    accuracy                           0.99     12000\n",
      "   macro avg       0.91      0.89      0.90     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score: 0.7913306451612905\n"
     ]
    }
   ],
   "source": [
    "ftwo_score2 = fbeta_score(y_test, y_pred2, beta=2, pos_label='pos')\n",
    "\n",
    "print(f'F2 score: {ftwo_score2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove features that have importance scores less than 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158,  12,  96, 134,  74,  84,  79, 160,  21,  58,   8,  99,  43,\n",
       "       100,   7, 115, 118,   0,  66,  77,  85, 117, 113, 150,  42, 111,\n",
       "        18,  69,  71, 166, 148,  76,  17,  59,  37, 101, 116,  44, 135,\n",
       "        80,  23,  88, 159, 131,  97,  10, 152, 104,  90, 147, 119,  87,\n",
       "        67, 163, 167, 128,  32, 149,  60,  34,  53,  83, 156, 161,  13,\n",
       "       102,  64, 107,  57, 136,  70,  68, 125,  30, 143,  11,  48,  46,\n",
       "        95,  56,  28, 162,   3,  61, 120,  15, 109,  94, 157, 144,  16,\n",
       "       110,  19, 121,  54, 108,  65,  45,  92, 105, 114,  29,  38,  14,\n",
       "        75, 106,  72, 103,  78, 146,  73,  51,  41, 123,  62,  50,  26,\n",
       "        36, 137,   5,   1,  33,  35, 124, 133,  47,   2, 132, 145, 127,\n",
       "         6, 112, 151,  31,  63,  91,  86, 168, 155, 126,   4, 139, 130,\n",
       "       129,  27, 154, 153, 140, 122, 138,  89,  93, 141, 169])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[16:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00992092, 0.00918449, 0.00878533, 0.00840436, 0.00835163,\n",
       "       0.00815548, 0.00812579, 0.00763657, 0.00734242, 0.00732035,\n",
       "       0.00722092, 0.00718279, 0.00693032, 0.00692643, 0.00688676,\n",
       "       0.00684529, 0.00669871, 0.00662625, 0.00639502, 0.00636692,\n",
       "       0.0062915 , 0.00623109, 0.00609775, 0.0059425 , 0.00583507,\n",
       "       0.00571067, 0.00561239, 0.00559615, 0.00552748, 0.0054403 ,\n",
       "       0.00533179, 0.00533009, 0.00527272, 0.00524911, 0.00520385,\n",
       "       0.00507917, 0.00506447, 0.0048344 , 0.00475843, 0.00474338,\n",
       "       0.00461557, 0.00461312, 0.00451327, 0.00443795, 0.00441762,\n",
       "       0.00437936, 0.0043751 , 0.00436766, 0.00432342, 0.00429241,\n",
       "       0.00428164, 0.00426892, 0.00423991, 0.00418961, 0.00416185,\n",
       "       0.00414792, 0.00413232, 0.00412034, 0.0040471 , 0.00400137,\n",
       "       0.00396809, 0.00392587, 0.00387013, 0.0038654 , 0.00384064,\n",
       "       0.00382504, 0.00372782, 0.00370615, 0.00368909, 0.00355614,\n",
       "       0.00354263, 0.00349789, 0.00341123, 0.00341025, 0.00339257,\n",
       "       0.00335813, 0.00334912, 0.00330861, 0.0032489 , 0.00320097,\n",
       "       0.00316659, 0.00312591, 0.00311014, 0.003046  , 0.00298344,\n",
       "       0.00297381, 0.00270455, 0.00263384, 0.00258637, 0.00256436,\n",
       "       0.00256414, 0.00255631, 0.00253322, 0.00250537, 0.00250287,\n",
       "       0.00242797, 0.00242353, 0.00239558, 0.00235547, 0.00232542,\n",
       "       0.0023002 , 0.00224042, 0.00222781, 0.0022155 , 0.00216884,\n",
       "       0.00213165, 0.00211113, 0.00203299, 0.00197213, 0.00192901,\n",
       "       0.00192761, 0.00191748, 0.00190709, 0.00190377, 0.00182809,\n",
       "       0.00181356, 0.00178293, 0.00177718, 0.00175148, 0.00174134,\n",
       "       0.00171642, 0.0016989 , 0.00167419, 0.00155968, 0.00155588,\n",
       "       0.00153707, 0.0014685 , 0.00144149, 0.0014327 , 0.00138859,\n",
       "       0.00136538, 0.00133852, 0.00125928, 0.00111176, 0.00105636,\n",
       "       0.00084746, 0.00069487, 0.00064515, 0.00061784, 0.00042705,\n",
       "       0.00022433, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances[indices[16:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ed_000', 'ag_005', 'cj_000', 'de_000', 'bm_000', 'bx_000', 'br_000',\n",
       "       'ee_001', 'al_000', 'ba_005',\n",
       "       ...\n",
       "       'ar_000', 'dz_000', 'dy_000', 'dk_000', 'cs_008', 'di_000', 'cc_000',\n",
       "       'cg_000', 'dl_000', 'ef_000'],\n",
       "      dtype='object', length=154)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_features2 = columns[indices[16:]]\n",
    "removed_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure the dataset by removing these less importatnt features\n",
    "X_new2 = np.delete(X_imputed_scaled, indices[16:] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training/testing dataset\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_new2, y, test_size=0.2, random_state=3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search to find best parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model2 = LogisticRegression(random_state=3, class_weight='balanced', max_iter=3000, verbose=1)\n",
    "\n",
    "grid_search_cv_models2 = GridSearchCV(lr_model2, params_grid, cv=fold, scoring=ftwo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=3, shuffle=True),\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=3000, random_state=3,\n",
       "                                          verbose=1),\n",
       "             param_grid={'C': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02,\n",
       "       1.e+03, 1.e+04])},\n",
       "             scoring=make_scorer(fbeta_score, beta=2, pos_label=pos))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CV model for logistic regression\n",
    "grid_search_cv_models2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score during training: 0.6503491260753078, with params: {'C': 100.0}\n"
     ]
    }
   ],
   "source": [
    "print(f'The best score during training: {grid_search_cv_models2.best_score_}, with params: {grid_search_cv_models2.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = grid_search_cv_models2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "           Pred:pos  Pred:neg\n",
      "True:pos       187        13\n",
      "True:neg       347     11453\n"
     ]
    }
   ],
   "source": [
    "conf_mat3 = get_confusion_matrix(y_pred3)\n",
    "print(f'Confusion matrix:\\n {conf_mat3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 9970\n"
     ]
    }
   ],
   "source": [
    "total_cost3 = get_total_cost(type1_error=347, type2_error=13)\n",
    "print(f'Total cost: {total_cost3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.97      0.98     11800\n",
      "         pos       0.35      0.94      0.51       200\n",
      "\n",
      "    accuracy                           0.97     12000\n",
      "   macro avg       0.67      0.95      0.75     12000\n",
      "weighted avg       0.99      0.97      0.98     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score: 0.7008995502248877\n"
     ]
    }
   ],
   "source": [
    "ftwo_score3 = fbeta_score(y_test, y_pred3, beta=2, pos_label='pos')\n",
    "\n",
    "print(f'F2 score: {ftwo_score3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "xgb_model2 = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric='aucpr', random_state=3, scale_pos_weight=estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='aucpr',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=3, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=59, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = xgb_model2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "           Pred:pos  Pred:neg\n",
      "True:pos       156        44\n",
      "True:neg        62     11738\n"
     ]
    }
   ],
   "source": [
    "conf_mat4 = get_confusion_matrix(y_pred4)\n",
    "print(f'Confusion matrix:\\n {conf_mat4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost: 22620\n"
     ]
    }
   ],
   "source": [
    "total_cost4 = get_total_cost(type1_error=62, type2_error=44)\n",
    "print(f'Total cost: {total_cost4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      0.99      1.00     11800\n",
      "         pos       0.72      0.78      0.75       200\n",
      "\n",
      "    accuracy                           0.99     12000\n",
      "   macro avg       0.86      0.89      0.87     12000\n",
      "weighted avg       0.99      0.99      0.99     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2 score: 0.7662082514734776\n"
     ]
    }
   ],
   "source": [
    "ftwo_score4 = fbeta_score(y_test, y_pred4, beta=2, pos_label='pos')\n",
    "\n",
    "print(f'F2 score: {ftwo_score4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bit497e650d671a465a832873f585116d0b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
